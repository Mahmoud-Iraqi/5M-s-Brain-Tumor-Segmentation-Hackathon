# ===============================# model.py# ===============================# Brain Tumor Segmentation: ResNet34-UNet# Author: Manar# Modular, clean & ready for Kaggle/GitHub# ===============================import torchimport torch.nn as nnimport torch.nn.functional as Fimport torchvision.models as models# ===============================# ConvBlock for Decoder# ===============================class ConvBlock(nn.Module):    """Basic convolution block for decoder with 2 Conv layers + BN + ReLU"""    def __init__(self, in_channels, out_channels):        super().__init__()        self.conv = nn.Sequential(            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),            nn.BatchNorm2d(out_channels),            nn.ReLU(inplace=True),            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),            nn.BatchNorm2d(out_channels),            nn.ReLU(inplace=True)        )    def forward(self, x):        return self.conv(x)# ===============================# ResNet34 UNet# ===============================class ResNet34UNet(nn.Module):    def __init__(self, n_classes=4):        super().__init__()        # --- Encoder: Pretrained ResNet34 ---        resnet = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)                self.first_conv = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)        self.first_conv.weight.data[:, :3, :, :] = resnet.conv1.weight.data        self.first_conv.weight.data[:, 3, :, :] = resnet.conv1.weight.data[:, 0, :, :]        self.enc0 = nn.Sequential(self.first_conv, resnet.bn1, resnet.relu)  # 64 channels        self.pool0 = resnet.maxpool        self.enc1 = resnet.layer1  # 64        self.enc2 = resnet.layer2  # 128        self.enc3 = resnet.layer3  # 256        self.enc4 = resnet.layer4  # 512 Bottleneck        # --- Decoder ---        self.up4 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        self.dec4 = ConvBlock(512 + 256, 256)        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        self.dec3 = ConvBlock(256 + 128, 128)        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        self.dec2 = ConvBlock(128 + 64, 64)        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        self.dec1 = ConvBlock(64 + 64, 64)        # Final output layer        self.final = nn.Conv2d(64, n_classes, kernel_size=1)    # ===============================    # Forward pass    # ===============================    def forward(self, x):        # Encoder        x0 = self.enc0(x)        # 64, H/2, W/2        x_pool = self.pool0(x0)  # 64, H/4, W/4        x1 = self.enc1(x_pool)   # 64        x2 = self.enc2(x1)       # 128        x3 = self.enc3(x2)       # 256        x4 = self.enc4(x3)       # 512        # Decoder + Skip Connections        d4 = self.up4(x4)        d4 = torch.cat([d4, x3], dim=1)        d4 = self.dec4(d4)        d3 = self.up3(d4)        d3 = torch.cat([d3, x2], dim=1)        d3 = self.dec3(d3)        d2 = self.up2(d3)        d2 = torch.cat([d2, x1], dim=1)        d2 = self.dec2(d2)        d1 = self.up1(d2)        # Adjust size if needed        if d1.size()[2:] != x0.size()[2:]:            d1 = F.interpolate(d1, size=x0.size()[2:], mode='bilinear', align_corners=True)        d1 = torch.cat([d1, x0], dim=1)        d1 = self.dec1(d1)        # Final upsample to original input size (128x128)        out = self.final(d1)        out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=True)        return out
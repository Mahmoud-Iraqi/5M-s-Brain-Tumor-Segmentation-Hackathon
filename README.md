<div align="center">

# ğŸ§  NeuroSeg AI - Brain Tumor Segmentation

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Demo](https://img.shields.io/badge/Demo-Live-brightgreen.svg)](https://neuroseg_ai.datacraft.in.net/)

**AI-Powered Brain Tumor Segmentation using Deep Learning**

*Automatic segmentation of glioma sub-regions from 3D MRI scans*

[ğŸŒ Live Demo](https://neuroseg_ai.datacraft.in.net/) â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/spaces/manarsaber11/BrainTumor) â€¢ [ğŸ“Š Competition](https://www.kaggle.com/competitions/instant-odc-ai-hackathon/)

</div>

---

## ğŸ“‹ Overview

This repository contains our solution for the **Brain Tumor Segmentation Challenge**, where we developed deep learning models to automatically segment glioma sub-regions from multi-parametric MRI (mpMRI) scans. Our solution achieved **89% validation accuracy** and **76% on the competition leaderboard** using the Mean Dice Coefficient metric.

### ğŸ¯ Challenge Description

Gliomas are the most common primary brain malignancies with different degrees of aggressiveness and heterogeneous histological sub-regions. This project tackles the instance segmentation task of outlining exact tumor boundaries in 3D space.

**Tumor Classes:**
| Label | Class | Description |
|-------|-------|-------------|
| 1 | Necrotic Tumor Core (NCR) | Dead tissue inside the tumor |
| 2 | Peritumoral Edema (ED) | Swelling surrounding the tumor |
| 4 | GD-enhancing Tumor (ET) | Active, growing part of the tumor |

---

## ğŸ† Results

<div align="center">

| Model | Architecture | Validation Accuracy | Leaderboard Score |
|-------|-------------|---------------------|-------------------|
| Pipeline 1 | ResNet34-UNet | **89%** | **76%** |
| Pipeline 2 | Residual U-Net 2D | **86%** | **76%** |

</div>

### ğŸ“¸ Model Predictions

<div align="center">

#### Ground Truth vs AI Prediction
<table>
<tr>
<td align="center"><b>Ground Truth</b></td>
<td align="center"><b>AI Prediction</b></td>
</tr>
<tr>
<td><img src="assets/model_prediction.jpeg" width="400"/></td>
<td><img src="assets/3d_visualization.png" width="400"/></td>
</tr>
</table>

#### Web Application Interface
<img src="assets/neuroseg_webapp.jpeg" width="700"/>

</div>

---

## ğŸ—ï¸ Architecture

### Pipeline 1: ResNet34-UNet (Pre_Trained)

A custom U-Net architecture with a pretrained ResNet34 encoder for robust feature extraction.

**Key Features:**
- ğŸ”¹ **Encoder**: Pretrained ResNet34 backbone (ImageNet weights)
- ğŸ”¹ **Input**: 4-channel MRI (FLAIR, T1, T1ce, T2) - modified first conv layer
- ğŸ”¹ **Decoder**: Custom ConvBlocks with skip connections
- ğŸ”¹ **Output**: 4-class segmentation map (128Ã—128)

```
ğŸ“ Pipeline 1/
â”œâ”€â”€ config.py      # Hyperparameters & settings
â”œâ”€â”€ dataset.py     # BraTS2D dataset loader
â”œâ”€â”€ model.py       # ResNet34-UNet architecture
â”œâ”€â”€ losses.py      # Dice + CrossEntropy combined loss
â””â”€â”€ train.py       # Training loop
```

**Configuration:**
```python
IMG_SIZE: 128
BATCH_SIZE: 64
LEARNING_RATE: 1e-4
EPOCHS: 20
SLICES_PER_PATIENT: 70
TARGET_PATIENTS: 544
```

### Pipeline 2: Residual U-Net 2D (Manual Architecture)

A lightweight custom residual U-Net built from scratch with skip connections and data augmentation.

**Key Features:**
- ğŸ”¹ **Architecture**: Custom ResidualBlocks with shortcut connections
- ğŸ”¹ **Channels**: 32 â†’ 64 â†’ 128 â†’ 256 (Encoder) â†’ Decoder
- ğŸ”¹ **Data Augmentation**: Rotation, flip, brightness, elastic transform
- ğŸ”¹ **Mixed Precision**: FP16 training with GradScaler
- ğŸ”¹ **Loss Function**: Weighted CrossEntropy + Dice Loss (class imbalance handling)

```
ğŸ“ Pipeline 2/
â”œâ”€â”€ config2.py     # Hyperparameters & settings
â”œâ”€â”€ dataset.py     # Dataset with augmentations
â”œâ”€â”€ model2.py      # Residual U-Net architecture
â”œâ”€â”€ loses.py       # Combined loss with class weights
â”œâ”€â”€ metric.py      # Dice score metric
â”œâ”€â”€ train2.py      # Training with mixed precision
â”œâ”€â”€ inference.py   # 3D volume inference
â””â”€â”€ brats_unet2d_final (15).pth  # Trained model weights
```

**Configuration:**
```python
IMG_SIZE: 128
BATCH_SIZE: 64
LEARNING_RATE: 3e-4
EPOCHS: 20
SLICES_PER_PATIENT: 75
TARGET_PATIENTS: 344
```

---

## ğŸ“Š Dataset

The data is derived from the **BraTS (Brain Tumor Segmentation) Challenge**, consisting of multi-parametric MRI scans.

**MRI Modalities:**
| Modality | Description |
|----------|-------------|
| **T1** (Native) | Useful for structural analysis |
| **T1ce** (Post-contrast) | Highlights enhancing tumor (active cells) |
| **T2** (T2-weighted) | Shows brain outline and fluids |
| **FLAIR** | Critical for detecting edema (swelling) |

All files are in NIfTI (`.nii.gz`) format.

---

## ğŸš€ Getting Started

### Prerequisites

```bash
pip install torch torchvision nibabel opencv-python numpy albumentations tqdm
```

### Training

**Pipeline 1:**
```bash
cd "Pipeline 1"
python train.py
```

**Pipeline 2:**
```bash
cd "Pipeline 2"
python train2.py
```

### Inference

```python
from Pipeline2.model2 import ResUNet2D

model = ResUNet2D(n_classes=4)
model.load_state_dict(torch.load("Pipeline 2/brats_unet2d_final (15).pth"))
model.eval()
```

---

## ğŸŒ Deployment

### Web Application
Our model is deployed as an interactive web application:

ğŸ”— **Live Demo**: [https://neuroseg_ai.datacraft.in.net/](https://neuroseg_ai.datacraft.in.net/)

ğŸ“‚ **Web Application Source Code**: [https://github.com/MostafaAyman3/Revesion/](https://github.com/MostafaAyman3/Revesion/)

**Features:**
- ğŸ“¤ Upload MRI scans in NIfTI format
- ğŸ–¼ï¸ 2D slice visualization with modality selection
- ğŸ§Š Interactive 3D brain tumor rendering
- ğŸ“Š Segmentation metrics display
- ğŸ“¥ Export analysis reports

### Hugging Face Spaces
Also available on Hugging Face for easy access and experimentation.

---

## ğŸ“ˆ Evaluation Metric

Submissions are evaluated using the **Mean Dice Coefficient**:

$$\text{Dice} = \frac{2|P \cap G|}{|P| + |G|}$$

Where:
- **P** = Predicted set of pixels
- **G** = Ground truth
- Score of **1.0** = Perfect match
- Score of **0.0** = No overlap

---

## ğŸ“ Project Structure

```
5M-s-Brain-Tumor-Segmentation-Hackathon/
â”œâ”€â”€ README.md
â”œâ”€â”€ EDA for Brain Tumor.ipynb    # Exploratory Data Analysis
â”œâ”€â”€ deployment video.mp4          # Deployment video
â”œâ”€â”€ Pipeline 1/                   # ResNet34-UNet
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ losses.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ Pipeline 2/                   # Residual U-Net 2D
â”‚   â”œâ”€â”€ config2.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ model2.py
â”‚   â”œâ”€â”€ loses.py
â”‚   â”œâ”€â”€ metric.py
â”‚   â”œâ”€â”€ train2.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ brats_unet2d_final (15).pth
â””â”€â”€ assets/
    â”œâ”€â”€ 3d_visualization.png
    â”œâ”€â”€ model_prediction.jpeg
    â””â”€â”€ neuroseg_webapp.jpeg
```

---

## ğŸ™ Acknowledgements

- **BraTS Challenge** - Data provided by the RSNA-ASNR-MICCAI BraTS Challenge
- **Kaggle** - Platform hosting the competition
- Contributing institutions and organizers for making this dataset available

---

## ğŸ‘¥ Team 5M

Built with â¤ï¸ for the Brain Tumor Segmentation Challenge

---

<div align="center">

**â­ Star this repository if you found it helpful!**

</div>

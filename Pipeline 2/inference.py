import osimport numpy as npimport nibabel as nibimport torchimport cv2from tqdm import tqdmfrom model import ResUNet2Dfrom config import ConfigDEVICE = Config["DEVICE"]IMG_SIZE = Config["IMG_SIZE"]NUM_CLASSES = Config["NUM_CLASSES"]# -----------------------------# Utils# -----------------------------def normalize_channel(ch):    if (ch > 0).sum() > 0:        p1, p99 = np.percentile(ch[ch > 0], (1, 99))        ch = np.clip((ch - p1) / (p99 - p1 + 1e-6), 0, 1)    return chdef load_slice(patient_path, patient_id, slice_idx):    images = []    for mod in ["flair", "t1", "t1ce", "t2"]:        p = os.path.join(patient_path, f"{patient_id}_{mod}.nii.gz")        vol = nib.load(p).get_fdata()        img = vol[..., slice_idx]        images.append(img)    img = np.stack(images, axis=-1)    # resize    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))    # normalize    for c in range(4):        img[..., c] = normalize_channel(img[..., c])    img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).float()    return img# -----------------------------# Inference on ONE patient# -----------------------------def infer_patient(patient_dir, model):    patient_id = os.path.basename(patient_dir)    seg_path = os.path.join(patient_dir, f"{patient_id}_seg.nii.gz")    proxy = nib.load(seg_path)    depth = proxy.shape[2]    pred_volume = np.zeros((IMG_SIZE, IMG_SIZE, depth), dtype=np.uint8)    model.eval()    with torch.no_grad():        for z in tqdm(range(depth), desc=f"Inference {patient_id}"):            img = load_slice(patient_dir, patient_id, z).to(DEVICE)            out = model(img)            pred = torch.argmax(out, dim=1).squeeze(0).cpu().numpy()            pred_volume[..., z] = pred    return pred_volume# -----------------------------# Main# -----------------------------if __name__ == "__main__":    MODEL_PATH = "/kaggle/input/brats-model/brats_75slices_best.pth"    PATIENT_PATH = "/kaggle/input/brain-tumor-segmentation-hackathon/BraTS2021_00000"    model = ResUNet2D(NUM_CLASSES).to(DEVICE)    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))    pred_3d = infer_patient(PATIENT_PATH, model)    print("âœ… Inference done")    print("Prediction shape:", pred_3d.shape)
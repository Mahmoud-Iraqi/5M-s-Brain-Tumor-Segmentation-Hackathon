import torch.nn as nnimport torch.nn.functional as Fclass ResidualBlock(nn.Module):    def __init__(self, in_c, out_c):        super().__init__()        self.conv = nn.Sequential(            nn.Conv2d(in_c,out_c,3,1,1),            nn.BatchNorm2d(out_c),            nn.ReLU(inplace=True),            nn.Conv2d(out_c,out_c,3,1,1),            nn.BatchNorm2d(out_c)        )        self.short = nn.Conv2d(in_c,out_c,1) if in_c!=out_c else nn.Identity()    def forward(self,x):        return F.relu(self.conv(x)+self.short(x))class ResUNet2D(nn.Module):    def __init__(self,n_classes=4):        super().__init__()        self.e1 = ResidualBlock(4,32)        self.e2 = ResidualBlock(32,64)        self.e3 = ResidualBlock(64,128)        self.b = ResidualBlock(128,256)        self.d3 = ResidualBlock(384,128)        self.d2 = ResidualBlock(192,64)        self.d1 = ResidualBlock(96,32)        self.out = nn.Conv2d(32,n_classes,1)        self.pool = nn.MaxPool2d(2)        self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=True)    def forward(self,x):        x1 = self.e1(x)        x2 = self.e2(self.pool(x1))        x3 = self.e3(self.pool(x2))        b = self.b(self.pool(x3))        x = self.d3(torch.cat([self.up(b),x3],1))        x = self.d2(torch.cat([self.up(x),x2],1))        x = self.d1(torch.cat([self.up(x),x1],1))        return self.out(x)